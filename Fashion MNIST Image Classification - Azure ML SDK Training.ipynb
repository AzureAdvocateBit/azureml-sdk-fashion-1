{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST Image Classification - Azure ML SDK Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add introduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  0.1.65\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your Azure ML workspace from thye config file you setup. The config file will look like below:\n",
    "\n",
    "![Config File](./images/configfile.JPG \"Config file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\amynic\\Documents\\CloudDeveloperAdvocate\\Deeplearning\\ai-world-summit\\config.json\n",
      "amyboyd_ws\twesteurope\tdeeplearning\twesteurope\n"
     ]
    }
   ],
   "source": [
    "# load workspace configuration from the config.json file in the current folder.\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment(Name: deeplearning_fashion,\n",
      "Workspace: amyboyd_ws)\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'deeplearning_fashion'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "print(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Cloud Compute Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating a new compute target...\n",
      "Creating\n",
      "succeeded.............\n",
      "BatchAI wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'allocationState': 'resizing', 'allocationStateTransitionTime': '2018-10-08T16:56:45.067000+00:00', 'creationTime': '2018-10-08T16:56:45.067000+00:00', 'currentNodeCount': 1, 'errors': None, 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preparingNodeCount': 1, 'runningNodeCount': 0, 'unusableNodeCount': 0}, 'provisioningState': 'succeeded', 'provisioningStateTransitionTime': '2018-10-08T16:57:05.081000+00:00', 'scaleSettings': {'manual': None, 'autoScale': {'maximumNodeCount': 5, 'minimumNodeCount': 1, 'initialNodeCount': 1}}, 'vmPriority': 'dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, BatchAiCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "batchai_cluster_name = \"traincluster\"\n",
    "\n",
    "try:\n",
    "    # look for the existing cluster by name\n",
    "    compute_target = ComputeTarget(workspace=ws, name=batchai_cluster_name)\n",
    "    if type(compute_target) is BatchAiCompute:\n",
    "        print('found compute target {}, just use it.'.format(batchai_cluster_name))\n",
    "    else:\n",
    "        print('{} exists but it is not a Batch AI cluster. Please choose a different name.'.format(batchai_cluster_name))\n",
    "except ComputeTargetException:\n",
    "    print('creating a new compute target...')\n",
    "    compute_config = BatchAiCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\", # small CPU-based VM\n",
    "                                                                #vm_priority='lowpriority', # optional\n",
    "                                                                autoscale_enabled=True,\n",
    "                                                                cluster_min_nodes=1, \n",
    "                                                                cluster_max_nodes=5)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, batchai_cluster_name, compute_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # Use the 'status' property to get a detailed status for the current cluster. \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './keras-fashion'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureFile amyboydws4528596861 azureml-filestore-848d7cfa-9e06-44f5-9ed0-5f6d3e4d8c28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_6ead2fc076dc47578af36b8dcce207d6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "ds.upload(src_dir='./data', target_path='fashiondata', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write train.py file and save model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./keras-fashion/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]= \"2\"\n",
    "print(\"tensorflow Version is: \" + str(tf.__version__))\n",
    "\n",
    "import numpy as np\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras import backend as K\n",
    "print(os.environ['KERAS_BACKEND'])\n",
    "\n",
    "#Fashion MNIST Dataset CNN model development: https://github.com/zalandoresearch/fashion-mnist\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import utils, losses, optimizers\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "# let user feed in 2 parameters, the location of the data files (from datastore), and the regularization rate of the logistic regression model\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "args = parser.parse_args()\n",
    "\n",
    "data_folder = os.path.join(args.data_folder, 'keras-fashion')\n",
    "print('Data folder:', data_folder)\n",
    "\n",
    "#variables\n",
    "num_classes = 10\n",
    "batch_size = 128\n",
    "epochs = 24\n",
    "img_rows,img_cols = 28,28\n",
    "\n",
    "#data for train and testing\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"Top\",          # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Jumper\",       # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Trainer\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, sep = '\\n')\n",
    "\n",
    "#data pre-processing\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test,  num_classes)\n",
    "\n",
    "#formatting issues for depth of image (greyscale = 1) with different kernels (tensorflow, cntk, etc)\n",
    "if K.image_data_format()== 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0],1,img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0],img_rows, img_cols,1)\n",
    "    input_shape = (img_rows, img_cols,1)\n",
    "    \n",
    "#Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding = 'same', activation = 'relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# get hold of the current run\n",
    "run = Run.get_submitted_run()\n",
    "\n",
    "print('Train a deep learning model')\n",
    "model.compile(loss=losses.categorical_crossentropy, optimizer=optimizers.Adam(), metrics=['accuracy'])\n",
    "hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "#evaluate the model on the test data\n",
    "print('Predict the test set')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Loss: ', score[0])\n",
    "print('Test Accuracy: ', score[1])\n",
    "\n",
    "# calculate accuracy on the prediction\n",
    "print('Accuracy is', score[1])\n",
    "\n",
    "run.log('accuracy', np.float(score[1]))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "model.save('outputs/model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model in the cloud for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./keras-fashion\\\\utils.py'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.copy('utils.py', script_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount()\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script='train.py',\n",
    "                conda_packages=['keras', 'scikit-learn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>deeplearning_fashion</td><td>deeplearning_fashion_1539020034713</td><td>azureml.scriptrun</td><td>Running</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/a2a1fc9f-5671-4479-8922-ad16e34c0fdc/resourceGroups/deeplearning/providers/Microsoft.MachineLearningServices/workspaces/amyboyd_ws/experiments/deeplearning_fashion/runs/deeplearning_fashion_1539020034713\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: deeplearning_fashion,\n",
       "Id: deeplearning_fashion_1539020034713,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = exp.submit(config=est)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf031522977e4a4696ed524a4b1bcf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True) # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9223}\n"
     ]
    }
   ],
   "source": [
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azureml-logs/60_control_log.txt', 'azureml-logs/80_driver_log.txt', 'outputs/model.h5', 'driver_log', 'azureml-logs/azureml.log', 'azureml-logs/55_batchai_execution.txt']\n"
     ]
    }
   ],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are you happy with the model??? Register it in Azure Machine Learning to manage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# register model \n",
    "model = run.register_model(model_name='keras_dl_fashion', model_path='outputs/')\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy up Compute Resource when not in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optionally, delete the Azure Managed Compute cluster\n",
    "compute_target.delete()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [myenv]",
   "language": "python",
   "name": "Python [myenv]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
